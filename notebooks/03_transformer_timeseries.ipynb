{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764e0bfb-09c7-4e2a-85a1-a8c1ea8ff31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Core\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# PyTorch\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# Scaling & metrics\n",
    "# ============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility\n",
    "# ============================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6edd95-dd79-4968-af29-d2a48ea0544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available (WSL should expose GPU through NVIDIA drivers)\n",
    "# However since pytorch cuda = 12.8 work with latest blackwell RTX5080\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f056c1-5437-4a48-9864-0abb693c25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] options: (4195810, 12)\n",
      "[SPY] daily+garch: (3521, 8)\n",
      "[AAPL] options: (1562105, 12)\n",
      "[AAPL] daily+garch: (2011, 8)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load CLEAN datasets (OPTIONS + DAILY WITH GARCH)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "ASSETS = {\n",
    "    \"SPY\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_SPY.csv\",\n",
    "        \"daily\":   DATA_DIR / \"spy_with_garch.csv\",\n",
    "    },\n",
    "    \"AAPL\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_AAPL.csv\",\n",
    "        \"daily\":   DATA_DIR / \"aapl_with_garch.csv\",\n",
    "    }\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for asset, cfg in ASSETS.items():\n",
    "    opts = pd.read_csv(\n",
    "        cfg[\"options\"],\n",
    "        parse_dates=[\"QUOTE_DATE\", \"EXPIRE_DATE\"]\n",
    "    )\n",
    "\n",
    "    daily = pd.read_csv(\n",
    "        cfg[\"daily\"],\n",
    "        parse_dates=[\"Date\"]\n",
    "    )\n",
    "\n",
    "    assert \"log_return\" in daily.columns\n",
    "    assert \"garch_vol\" in daily.columns\n",
    "\n",
    "    datasets[asset] = {\n",
    "        \"opts\": opts,\n",
    "        \"daily\": daily\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] options:\", opts.shape)\n",
    "    print(f\"[{asset}] daily+garch:\", daily.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f91ba7-399c-4cde-8fb2-d092223423af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] merged rows: 4169845\n",
      "[AAPL] merged rows: 1552960\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 80 / 10 / 10 time-based split (per asset)\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# Merge macro features into options (per asset)\n",
    "# ============================================================\n",
    "\n",
    "merged_data = {}\n",
    "\n",
    "for asset, data_dict in datasets.items():\n",
    "    opts  = data_dict[\"opts\"]\n",
    "    daily = data_dict[\"daily\"]\n",
    "\n",
    "    daily_small = daily[[\"Date\", \"Close\", \"log_return\", \"garch_vol\"]].copy()\n",
    "    daily_small = daily_small.rename(columns={\n",
    "        \"Date\": \"QUOTE_DATE\",\n",
    "        \"Close\": f\"{asset}_CLOSE\"\n",
    "    })\n",
    "\n",
    "    merged = opts.merge(daily_small, on=\"QUOTE_DATE\", how=\"left\")\n",
    "    merged = merged.dropna(subset=[\"log_return\", \"garch_vol\", f\"{asset}_CLOSE\"])\n",
    "    merged = merged.sort_values(\"QUOTE_DATE\").reset_index(drop=True)\n",
    "\n",
    "    merged_data[asset] = merged\n",
    "    print(f\"[{asset}] merged rows:\", len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ed1fe-fc3c-44f4-a63f-acdb2dcdb345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] train=2330311 | val=1024018 | test=815516\n",
      "[AAPL] train=1204151 | val=161572 | test=187237\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 80 / 10 / 10 time-based split (per asset)\n",
    "# ============================================================\n",
    "\n",
    "splits = {}\n",
    "\n",
    "for asset, df in merged_data.items():\n",
    "    dates = df[\"QUOTE_DATE\"].sort_values().unique()\n",
    "    n = len(dates)\n",
    "\n",
    "    train_end = int(0.8 * n)\n",
    "    val_end   = int(0.9 * n)\n",
    "\n",
    "    train_dates = dates[:train_end]\n",
    "    val_dates   = dates[train_end:val_end]\n",
    "    test_dates  = dates[val_end:]\n",
    "\n",
    "    splits[asset] = {\n",
    "        \"train\": df[df[\"QUOTE_DATE\"].isin(train_dates)],\n",
    "        \"val\":   df[df[\"QUOTE_DATE\"].isin(val_dates)],\n",
    "        \"test\":  df[df[\"QUOTE_DATE\"].isin(test_dates)],\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] train={len(splits[asset]['train'])} | \"\n",
    "          f\"val={len(splits[asset]['val'])} | \"\n",
    "          f\"test={len(splits[asset]['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3291bede-fece-4075-b5b2-953997d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features = {}\n",
    "option_features = [\"UNDERLYING_LAST\", \"DTE\", \"MONEINESS\"]\n",
    "target_col = \"C_MID\"\n",
    "\n",
    "for asset in splits:\n",
    "    market_features[asset] = [\n",
    "        f\"{asset}_CLOSE\",\n",
    "        \"log_return\",\n",
    "        \"garch_vol\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8aa9c2a-384d-4e21-b601-40d54723a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Scaling\n",
    "# ------------------------------------------------------------\n",
    "# VERY IMPORTANT:\n",
    "# - Scalers are fit only on training data\n",
    "# - Prevents future information leakage\n",
    "# ============================================================\n",
    "# ============================================================\n",
    "# Scaling (NO SettingWithCopyWarning)\n",
    "# ============================================================\n",
    "\n",
    "scalers = {}\n",
    "scaled  = {}\n",
    "\n",
    "for asset, split in splits.items():\n",
    "    # Explicit copies (IMPORTANT)\n",
    "    train_df = split[\"train\"].copy()\n",
    "    val_df   = split[\"val\"].copy()\n",
    "    test_df  = split[\"test\"].copy()\n",
    "\n",
    "    scaler_m = StandardScaler()\n",
    "    scaler_o = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    # ---- market features ----\n",
    "    train_df.loc[:, market_features[asset]] = scaler_m.fit_transform(\n",
    "        train_df[market_features[asset]]\n",
    "    )\n",
    "    val_df.loc[:, market_features[asset]] = scaler_m.transform(\n",
    "        val_df[market_features[asset]]\n",
    "    )\n",
    "    test_df.loc[:, market_features[asset]] = scaler_m.transform(\n",
    "        test_df[market_features[asset]]\n",
    "    )\n",
    "\n",
    "    # ---- option features ----\n",
    "    train_df.loc[:, option_features] = scaler_o.fit_transform(\n",
    "        train_df[option_features]\n",
    "    )\n",
    "    val_df.loc[:, option_features] = scaler_o.transform(\n",
    "        val_df[option_features]\n",
    "    )\n",
    "    test_df.loc[:, option_features] = scaler_o.transform(\n",
    "        test_df[option_features]\n",
    "    )\n",
    "\n",
    "    # ---- target ----\n",
    "    train_df.loc[:, target_col] = scaler_y.fit_transform(\n",
    "        train_df[[target_col]]\n",
    "    )\n",
    "    val_df.loc[:, target_col] = scaler_y.transform(\n",
    "        val_df[[target_col]]\n",
    "    )\n",
    "    test_df.loc[:, target_col] = scaler_y.transform(\n",
    "        test_df[[target_col]]\n",
    "    )\n",
    "\n",
    "    scalers[asset] = (scaler_m, scaler_o, scaler_y)\n",
    "\n",
    "    # Overwrite splits with scaled, SAFE versions\n",
    "    splits[asset] = {\n",
    "        \"train\": train_df,\n",
    "        \"val\":   val_df,\n",
    "        \"test\":  test_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb8579e-4afa-441a-b034-4208042657e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building sequences for SPY\n",
      "[SPY] Train: (2330301, 10, 3)\n",
      "[SPY] Val  : (1024008, 10, 3)\n",
      "[SPY] Test : (815506, 10, 3)\n",
      "\n",
      "Building sequences for AAPL\n",
      "[AAPL] Train: (1204141, 10, 3)\n",
      "[AAPL] Val  : (161562, 10, 3)\n",
      "[AAPL] Test : (187227, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Sequence creation\n",
    "# ------------------------------------------------------------\n",
    "# Each sample:\n",
    "# - Uses past N days of market state\n",
    "# - Predicts option price today\n",
    "#\n",
    "# Example (seq_len=10):\n",
    "# X = market[t-9 ... t]\n",
    "# y = option_price[t]\n",
    "# ============================================================\n",
    "# ============================================================\n",
    "# Sequence creation (PER ASSET, SAFE NUMERIC TYPES)\n",
    "# ------------------------------------------------------------\n",
    "# Enforces float32 to avoid numpy.object_ issues\n",
    "# ============================================================\n",
    "\n",
    "SEQ_LEN = 10\n",
    "\n",
    "def build_sequences(df, market_cols, option_cols, target_col):\n",
    "    X_seq = []\n",
    "    X_opt = []\n",
    "    y = []\n",
    "\n",
    "    # Ensure numeric arrays upfront (CRITICAL)\n",
    "    market_arr = df[market_cols].astype(np.float32).values\n",
    "    option_arr = df[option_cols].astype(np.float32).values\n",
    "    target_arr = df[target_col].astype(np.float32).values\n",
    "\n",
    "    for i in range(SEQ_LEN, len(df)):\n",
    "        X_seq.append(market_arr[i-SEQ_LEN:i])\n",
    "        X_opt.append(option_arr[i])\n",
    "        y.append(target_arr[i])\n",
    "\n",
    "    return (\n",
    "        np.asarray(X_seq, dtype=np.float32),\n",
    "        np.asarray(X_opt, dtype=np.float32),\n",
    "        np.asarray(y, dtype=np.float32).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Build sequences PER ASSET\n",
    "# ----------------------------\n",
    "X_seq_train, X_opt_train, y_train = {}, {}, {}\n",
    "X_seq_val,   X_opt_val,   y_val   = {}, {}, {}\n",
    "X_seq_test,  X_opt_test,  y_test  = {}, {}, {}\n",
    "\n",
    "for asset, split in splits.items():\n",
    "    print(f\"\\nBuilding sequences for {asset}\")\n",
    "\n",
    "    X_seq_train[asset], X_opt_train[asset], y_train[asset] = build_sequences(\n",
    "        split[\"train\"],\n",
    "        market_features[asset],\n",
    "        option_features,\n",
    "        target_col\n",
    "    )\n",
    "\n",
    "    X_seq_val[asset], X_opt_val[asset], y_val[asset] = build_sequences(\n",
    "        split[\"val\"],\n",
    "        market_features[asset],\n",
    "        option_features,\n",
    "        target_col\n",
    "    )\n",
    "\n",
    "    X_seq_test[asset], X_opt_test[asset], y_test[asset] = build_sequences(\n",
    "        split[\"test\"],\n",
    "        market_features[asset],\n",
    "        option_features,\n",
    "        target_col\n",
    "    )\n",
    "\n",
    "    print(f\"[{asset}] Train:\", X_seq_train[asset].shape)\n",
    "    print(f\"[{asset}] Val  :\", X_seq_val[asset].shape)\n",
    "    print(f\"[{asset}] Test :\", X_seq_test[asset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dbd1e0f-84d0-4e94-9118-c4075c584b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(X_opt_train[\"SPY\"].dtype)\n",
    "print(X_opt_train[\"AAPL\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1cd991-856e-4f5a-a449-e5203ada0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Torch Dataset for time-series Transformer\n",
    "# ============================================================\n",
    "\n",
    "class OptionSeqDataset(Dataset):\n",
    "    def __init__(self, X_seq, X_opt, y):\n",
    "        self.X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "        self.X_opt = torch.tensor(X_opt, dtype=torch.float32)\n",
    "        self.y     = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_seq[idx], self.X_opt[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64c522f-e1e6-4f86-abae-90ed1a00f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DataLoaders for SPY\n",
      "[SPY] loaders ready\n",
      "Building DataLoaders for AAPL\n",
      "[AAPL] loaders ready\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# DataLoaders (GPU-friendly)\n",
    "# ------------------------------------------------------------\n",
    "# Notes:\n",
    "# - Keep tensors on CPU, move per-batch to GPU in the training loop\n",
    "# - pin_memory speeds CPU->GPU transfer\n",
    "# ------------------------------------------------------------\n",
    "# ============================================================\n",
    "# DataLoaders (per asset, GPU-friendly)\n",
    "# ============================================================\n",
    "\n",
    "loaders = {}\n",
    "pin = (device.type == \"cuda\")\n",
    "\n",
    "for asset in [\"SPY\", \"AAPL\"]:\n",
    "    print(f\"Building DataLoaders for {asset}\")\n",
    "\n",
    "    train_ds = OptionSeqDataset(\n",
    "        X_seq_train[asset],\n",
    "        X_opt_train[asset],\n",
    "        y_train[asset]\n",
    "    )\n",
    "    val_ds = OptionSeqDataset(\n",
    "        X_seq_val[asset],\n",
    "        X_opt_val[asset],\n",
    "        y_val[asset]\n",
    "    )\n",
    "    test_ds = OptionSeqDataset(\n",
    "        X_seq_test[asset],\n",
    "        X_opt_test[asset],\n",
    "        y_test[asset]\n",
    "    )\n",
    "\n",
    "    loaders[asset] = {\n",
    "        \"train\": DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=512,        # IMPORTANT: smaller batch for Transformer\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=pin,\n",
    "            persistent_workers=True\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=pin,\n",
    "            persistent_workers=True\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=pin,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e138474-3568-4193-bfd1-741a3eaa663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Transformer model\n",
    "# ------------------------------------------------------------\n",
    "# - Encodes market history\n",
    "# - Combines with option static features\n",
    "# ============================================================\n",
    "\n",
    "class OptionTransformer(nn.Module):\n",
    "    def __init__(self, market_dim, option_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.market_proj = nn.Linear(market_dim, 32)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=32,\n",
    "            nhead=4,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=2\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32 + option_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X_seq, X_opt):\n",
    "        # Project market features\n",
    "        x = self.market_proj(X_seq)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Use last timestep embedding\n",
    "        x_last = x[:, -1, :]\n",
    "\n",
    "        # Concatenate static option features\n",
    "        combined = torch.cat([x_last, X_opt], dim=1)\n",
    "\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08d0596-7c21-4ce1-9cda-cc5e6f8d37e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training Transformer for SPY\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.020654 | Val MSE: 0.028337\n",
      "Epoch 02 | Train MSE: 0.001089 | Val MSE: 0.048238\n",
      "Epoch 03 | Train MSE: 0.000929 | Val MSE: 0.023708\n",
      "Epoch 04 | Train MSE: 0.000665 | Val MSE: 0.021628\n",
      "Epoch 05 | Train MSE: 0.000671 | Val MSE: 0.024982\n",
      "Epoch 06 | Train MSE: 0.000697 | Val MSE: 0.019159\n",
      "Epoch 07 | Train MSE: 0.000619 | Val MSE: 0.019011\n",
      "Epoch 08 | Train MSE: 0.000559 | Val MSE: 0.020201\n",
      "Epoch 09 | Train MSE: 0.000484 | Val MSE: 0.018587\n",
      "Epoch 10 | Train MSE: 0.000360 | Val MSE: 0.021747\n",
      "Epoch 11 | Train MSE: 0.000422 | Val MSE: 0.020535\n",
      "Early stopping at epoch 11\n",
      "\n",
      "==============================\n",
      " Training Transformer for AAPL\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.114541 | Val MSE: 0.008125\n",
      "Epoch 02 | Train MSE: 0.005002 | Val MSE: 0.002023\n",
      "Epoch 03 | Train MSE: 0.001411 | Val MSE: 0.001419\n",
      "Epoch 04 | Train MSE: 0.000898 | Val MSE: 0.001300\n",
      "Epoch 05 | Train MSE: 0.000693 | Val MSE: 0.001539\n",
      "Epoch 06 | Train MSE: 0.000579 | Val MSE: 0.001306\n",
      "Early stopping at epoch 6\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Training loop with EARLY STOPPING (per asset) with GPU\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "EPOCHS = 20\n",
    "PATIENCE = 2\n",
    "\n",
    "results = {}\n",
    "\n",
    "for asset in [\"SPY\", \"AAPL\"]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Training Transformer for {asset}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    train_loader = loaders[asset][\"train\"]\n",
    "    val_loader   = loaders[asset][\"val\"]\n",
    "\n",
    "    model = OptionTransformer(\n",
    "        market_dim=len(market_features[asset]),\n",
    "        option_dim=len(option_features)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    patience_ctr = 0\n",
    "\n",
    "    train_hist, val_hist = [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # -------- TRAIN --------\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for X_seq, X_opt, y in train_loader:\n",
    "            X_seq = X_seq.to(device, non_blocking=True)\n",
    "            X_opt = X_opt.to(device, non_blocking=True)\n",
    "            y     = y.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(X_seq, X_opt)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # -------- VALIDATE --------\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_seq, X_opt, y in val_loader:\n",
    "                X_seq = X_seq.to(device, non_blocking=True)\n",
    "                X_opt = X_opt.to(device, non_blocking=True)\n",
    "                y     = y.to(device, non_blocking=True)\n",
    "\n",
    "                preds = model(X_seq, X_opt)\n",
    "                val_losses.append(loss_fn(preds, y).item())\n",
    "\n",
    "        train_mse = np.mean(train_losses)\n",
    "        val_mse   = np.mean(val_losses)\n",
    "\n",
    "        train_hist.append(train_mse)\n",
    "        val_hist.append(val_mse)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:02d} | \"\n",
    "            f\"Train MSE: {train_mse:.6f} | \"\n",
    "            f\"Val MSE: {val_mse:.6f}\"\n",
    "        )\n",
    "\n",
    "        # -------- EARLY STOP --------\n",
    "        if val_mse < best_val:\n",
    "            best_val = val_mse\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= PATIENCE:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "\n",
    "    results[asset] = {\n",
    "        \"model\": model,\n",
    "        \"best_val_mse\": best_val,\n",
    "        \"train_mse\": train_hist,\n",
    "        \"val_mse\": val_hist\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af35cac4-fc35-4839-989d-2b79fc3ab679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Test evaluation for SPY\n",
      "==============================\n",
      "[SPY] Test RMSE: 7.2919 (14.07%)\n",
      "[SPY] Test MAE : 5.1454 (9.93%)\n",
      "\n",
      "==============================\n",
      " Test evaluation for AAPL\n",
      "==============================\n",
      "[AAPL] Test RMSE: 2.2521 (9.39%)\n",
      "[AAPL] Test MAE : 1.5432 (6.43%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Test evaluation (ONCE, after model selection)\n",
    "# ============================================================\n",
    "\n",
    "for asset in [\"SPY\", \"AAPL\"]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Test evaluation for {asset}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    model = results[asset][\"model\"]\n",
    "    test_loader = loaders[asset][\"test\"]\n",
    "    scaler_y = scalers[asset][2]   # target scaler\n",
    "\n",
    "    model.eval()\n",
    "    preds_all = []\n",
    "    y_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_seq, X_opt, y in test_loader:\n",
    "            X_seq = X_seq.to(device, non_blocking=True)\n",
    "            X_opt = X_opt.to(device, non_blocking=True)\n",
    "\n",
    "            preds = model(X_seq, X_opt)\n",
    "\n",
    "            preds_all.append(preds.cpu().numpy())\n",
    "            y_all.append(y.cpu().numpy())\n",
    "\n",
    "    preds = scaler_y.inverse_transform(np.vstack(preds_all))\n",
    "    true  = scaler_y.inverse_transform(np.vstack(y_all))\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true, preds))\n",
    "    mae  = mean_absolute_error(true, preds)\n",
    "\n",
    "    mean_price = true.mean()\n",
    "    print(f\"[{asset}] Test RMSE: {rmse:.4f} ({100*rmse/mean_price:.2f}%)\")\n",
    "    print(f\"[{asset}] Test MAE : {mae:.4f} ({100*mae/mean_price:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66728b-f0c1-4e9c-9620-d221475b4fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Option Pricing (WSL)",
   "language": "python",
   "name": "option_pricing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
