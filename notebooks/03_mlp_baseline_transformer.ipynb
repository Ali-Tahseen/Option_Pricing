{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89b4391-0d40-4b20-90e9-6a7921d911f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Core numerical libraries\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# PyTorch (MLP model)\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# Scaling and metrics\n",
    "# ============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility\n",
    "# ============================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94310362-ed21-41fd-86e5-e998f1e038b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5080\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available (WSL should expose GPU through NVIDIA drivers)\n",
    "# However since pytorch cuda = 12.8 work with latest blackwell RTX5080\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175bff18-8426-437b-9515-02d7112ab700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] options rows: 4195810\n",
      "[SPY] daily rows: 3521\n",
      "[AAPL] options rows: 1562105\n",
      "[AAPL] daily rows: 2011\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load CLEAN datasets (already prepared earlier)\n",
    "# ------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "ASSETS = {\n",
    "    \"SPY\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_SPY.csv\",\n",
    "        \"daily\":   DATA_DIR / \"spy_with_garch.csv\",\n",
    "        \"daily_date_col\": \"Date\",\n",
    "        \"daily_close_col\": \"Close\"\n",
    "    },\n",
    "    \"AAPL\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_AAPL.csv\",\n",
    "        \"daily\":   DATA_DIR / \"aapl_with_garch.csv\",  # you must create this in Notebook 02\n",
    "        \"daily_date_col\": \"Date\",\n",
    "        \"daily_close_col\": \"Close\"\n",
    "    }\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for asset, cfg in ASSETS.items():\n",
    "    opts = pd.read_csv(cfg[\"options\"])\n",
    "    daily = pd.read_csv(cfg[\"daily\"], parse_dates=[cfg[\"daily_date_col\"]])\n",
    "\n",
    "    opts[\"QUOTE_DATE\"]  = pd.to_datetime(opts[\"QUOTE_DATE\"],  format=\"mixed\", errors=\"coerce\")\n",
    "    opts[\"EXPIRE_DATE\"] = pd.to_datetime(opts[\"EXPIRE_DATE\"], format=\"mixed\", errors=\"coerce\")\n",
    "    opts = opts.dropna(subset=[\"QUOTE_DATE\", \"EXPIRE_DATE\"])\n",
    "\n",
    "    daily = daily.sort_values(cfg[\"daily_date_col\"]).reset_index(drop=True)\n",
    "\n",
    "    datasets[asset] = {\n",
    "        \"opts\": opts,\n",
    "        \"daily\": daily\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] options rows:\", len(opts))\n",
    "    print(f\"[{asset}] daily rows:\", len(daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b92b68e-cc60-457b-a4c3-c120af06adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] merged rows: 4169845\n",
      "[AAPL] merged rows: 1552960\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Merge SPY and AAPL macro features into option dataset\n",
    "# ------------------------------------------------------------\n",
    "# Why?\n",
    "# - Options prices depend on:\n",
    "#   • underlying level\n",
    "#   • market returns\n",
    "#   • volatility regime\n",
    "# ============================================================\n",
    "\n",
    "merged_data = {}\n",
    "\n",
    "for asset, data_dict in datasets.items():\n",
    "    opts = data_dict[\"opts\"]\n",
    "    daily = data_dict[\"daily\"]\n",
    "\n",
    "    daily_small = daily[[\"Date\", \"Close\", \"log_return\", \"garch_vol\"]].copy()\n",
    "    daily_small = daily_small.rename(columns={\n",
    "        \"Date\": \"QUOTE_DATE\",\n",
    "        \"Close\": f\"{asset}_CLOSE\"\n",
    "    })\n",
    "\n",
    "    opts[\"QUOTE_DATE\"] = pd.to_datetime(opts[\"QUOTE_DATE\"])\n",
    "    daily_small[\"QUOTE_DATE\"] = pd.to_datetime(daily_small[\"QUOTE_DATE\"])\n",
    "\n",
    "    merged = opts.merge(daily_small, on=\"QUOTE_DATE\", how=\"left\")\n",
    "    merged = merged.dropna(subset=[\"log_return\", \"garch_vol\", f\"{asset}_CLOSE\"])\n",
    "\n",
    "    merged_data[asset] = merged\n",
    "\n",
    "    print(f\"[{asset}] merged rows:\", len(merged))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da572977-452e-4800-82ce-1684fcca02b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Black–Scholes pricing functions\n",
    "# ------------------------------------------------------------\n",
    "# Used as a structural baseline.\n",
    "# ML models will learn only the residual.\n",
    "# ============================================================\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def black_scholes_price(S, K, T, r, sigma, option_type=\"call\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    S : spot price\n",
    "    K : strike\n",
    "    T : time to maturity (years)\n",
    "    r : risk-free rate\n",
    "    sigma : volatility\n",
    "    option_type : \"call\" or \"put\"\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-8\n",
    "    T = np.maximum(T, eps)\n",
    "    sigma = np.maximum(sigma, eps)\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if option_type == \"call\":\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    else:\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d47c3d-3858-4538-a8f0-d0892c470a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Feature selection\n",
    "# ------------------------------------------------------------\n",
    "# These are standard option pricing drivers available at time t:\n",
    "#\n",
    "# UNDERLYING_LAST → option underlying spot\n",
    "# log_return     → return shock of the underlying\n",
    "# garch_vol      → volatility regime indicator\n",
    "# DTE            → time to maturity (theta decay)\n",
    "# MONEINESS      → intrinsic structure of the option\n",
    "#\n",
    "# NOTE:\n",
    "# - These features are used to PREDICT future option prices\n",
    "# - Target creation is done LATER (per asset and option type)\n",
    "# ============================================================\n",
    "\n",
    "feature_cols_base = [\n",
    "    \"UNDERLYING_LAST\",\n",
    "    \"log_return\",\n",
    "    \"garch_vol\",\n",
    "    \"DTE\",\n",
    "    \"MONEINESS\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Target configuration (do NOT create targets here)\n",
    "# ------------------------------------------------------------\n",
    "# We train SEPARATE models for:\n",
    "# - Call options (C_MID)\n",
    "# - Put  options (P_MID)\n",
    "#\n",
    "# Target is the NEXT-STEP log return of the option price,\n",
    "# constructed later inside the per-asset split loop.\n",
    "# ============================================================\n",
    "\n",
    "TARGETS = {\n",
    "    \"CALL\": \"C_MID\",\n",
    "    \"PUT\":  \"P_MID\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4900ba02-08e4-4c30-a9f4-e31c6cd479c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SPY] split:\n",
      "  Train: 2330311\n",
      "  Val  : 1024018\n",
      "  Test : 815516\n",
      "\n",
      "[AAPL] split:\n",
      "  Train: 1204151\n",
      "  Val  : 161572\n",
      "  Test : 187237\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 80/10/10 split (time-based split)\n",
    "# ============================================================\n",
    "\n",
    "splits = {}\n",
    "\n",
    "for asset, df in merged_data.items():\n",
    "    df = df.sort_values(\"QUOTE_DATE\").reset_index(drop=True)\n",
    "\n",
    "    unique_dates = df[\"QUOTE_DATE\"].sort_values().unique()\n",
    "    n_dates = len(unique_dates)\n",
    "\n",
    "    train_cut = int(0.8 * n_dates)\n",
    "    val_cut   = int(0.9 * n_dates)\n",
    "\n",
    "    train_dates = unique_dates[:train_cut]\n",
    "    val_dates   = unique_dates[train_cut:val_cut]\n",
    "    test_dates  = unique_dates[val_cut:]\n",
    "\n",
    "    train_data = df[df[\"QUOTE_DATE\"].isin(train_dates)]\n",
    "    val_data   = df[df[\"QUOTE_DATE\"].isin(val_dates)]\n",
    "    test_data  = df[df[\"QUOTE_DATE\"].isin(test_dates)]\n",
    "\n",
    "    splits[asset] = {\n",
    "        \"train\": train_data,\n",
    "        \"val\":   val_data,\n",
    "        \"test\":  test_data\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[{asset}] split:\")\n",
    "    print(\"  Train:\", len(train_data))\n",
    "    print(\"  Val  :\", len(val_data))\n",
    "    print(\"  Test :\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6046b3a-ec72-4068-b37c-6fc14ebc8e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " PURE BLACK–SCHOLES BENCHMARK \n",
      "==============================\n",
      "\n",
      "--- VAL ---\n",
      "SPY CALL | BS MAE: 5.102 (9.84%) | RMSE: 8.583 (16.56%)\n",
      "SPY PUT | BS MAE: 8.841 (37.13%) | RMSE: 13.711 (57.59%)\n",
      "AAPL CALL | BS MAE: 2.897 (8.59%) | RMSE: 5.650 (16.76%)\n",
      "AAPL PUT | BS MAE: 3.838 (15.09%) | RMSE: 6.728 (26.45%)\n",
      "\n",
      "--- TEST ---\n",
      "SPY CALL | BS MAE: 7.069 (13.64%) | RMSE: 11.651 (22.48%)\n",
      "SPY PUT | BS MAE: 6.266 (30.91%) | RMSE: 10.160 (50.11%)\n",
      "AAPL CALL | BS MAE: 3.219 (13.41%) | RMSE: 6.049 (25.21%)\n",
      "AAPL PUT | BS MAE: 3.335 (9.78%) | RMSE: 5.505 (16.15%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Pure Black–Scholes benchmark (NO ML)\n",
    "# ============================================================\n",
    "# This cell evaluates how well Black–Scholes alone prices options.\n",
    "# It provides the baseline that ML must beat.\n",
    "# ============================================================\n",
    "\n",
    "RISK_FREE_RATE = 0.02   # <-- DEFINE HERE (FIXES NameError)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" PURE BLACK–SCHOLES BENCHMARK \")\n",
    "print(\"==============================\")\n",
    "\n",
    "for split_name in [\"val\", \"test\"]:\n",
    "    print(f\"\\n--- {split_name.upper()} ---\")\n",
    "\n",
    "    for asset, asset_data in splits.items():\n",
    "        for opt_type, price_col in TARGETS.items():\n",
    "\n",
    "            # ------------------------------------------------\n",
    "            # Select correct split and clean prices\n",
    "            # ------------------------------------------------\n",
    "            df = asset_data[split_name].copy()\n",
    "            df = df.loc[df[price_col] > 0].copy()\n",
    "\n",
    "            # ------------------------------------------------\n",
    "            # Option type\n",
    "            # ------------------------------------------------\n",
    "            option_flag = \"call\" if opt_type == \"CALL\" else \"put\"\n",
    "\n",
    "            # ------------------------------------------------\n",
    "            # Black–Scholes price\n",
    "            # ------------------------------------------------\n",
    "            bs_prices = black_scholes_price(\n",
    "                S=df[\"UNDERLYING_LAST\"].values,\n",
    "                K=df[\"STRIKE\"].values,\n",
    "                T=df[\"DTE\"].values / 365.0,\n",
    "                r=RISK_FREE_RATE,\n",
    "                sigma=df[\"garch_vol\"].values,\n",
    "                option_type=option_flag\n",
    "            )\n",
    "\n",
    "            true_prices = df[price_col].values\n",
    "\n",
    "            # ------------------------------------------------\n",
    "            # Metrics\n",
    "            # ------------------------------------------------\n",
    "            mae  = mean_absolute_error(true_prices, bs_prices)\n",
    "            rmse = np.sqrt(mean_squared_error(true_prices, bs_prices))\n",
    "\n",
    "            mae_pct  = 100 * mae / np.mean(true_prices)\n",
    "            rmse_pct = 100 * rmse / np.mean(true_prices)\n",
    "\n",
    "            print(\n",
    "                f\"{asset} {opt_type} | \"\n",
    "                f\"BS MAE: {mae:.3f} ({mae_pct:.2f}%) | \"\n",
    "                f\"RMSE: {rmse:.3f} ({rmse_pct:.2f}%)\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba1bc820-2e05-4d78-b1a8-4a05bb4717ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY | CALL] BS residuals (clipped) ready\n",
      "[SPY | PUT] BS residuals (clipped) ready\n",
      "[AAPL | CALL] BS residuals (clipped) ready\n",
      "[AAPL | PUT] BS residuals (clipped) ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Target construction: Black–Scholes residuals (CLIPPED)\n",
    "# ------------------------------------------------------------\n",
    "# Target = log(C_market / C_BS)\n",
    "# Clipping prevents exponential blow-ups during reconstruction\n",
    "# ============================================================\n",
    "\n",
    "scaled = {}\n",
    "\n",
    "RISK_FREE_RATE = 0.02\n",
    "EPS = 1e-8\n",
    "RESID_CLIP = 1.0   # <-- KEY CHANGE (exp(±1) ≈ ×2.7)\n",
    "\n",
    "for asset, split in splits.items():\n",
    "    X_cols = feature_cols_base + [f\"{asset}_CLOSE\"]\n",
    "    scaled[asset] = {}\n",
    "\n",
    "    for opt_type, price_col in TARGETS.items():\n",
    "\n",
    "        df_train = split[\"train\"].copy()\n",
    "        df_val   = split[\"val\"].copy()\n",
    "        df_test  = split[\"test\"].copy()\n",
    "\n",
    "        option_flag = \"call\" if opt_type == \"CALL\" else \"put\"\n",
    "\n",
    "        for df_ in (df_train, df_val, df_test):\n",
    "\n",
    "            # ---- BS price at time t ----\n",
    "            df_[\"BS_PRICE\"] = black_scholes_price(\n",
    "                S=df_[\"UNDERLYING_LAST\"].values,\n",
    "                K=df_[\"STRIKE\"].values,\n",
    "                T=df_[\"DTE\"].values / 365.0,\n",
    "                r=RISK_FREE_RATE,\n",
    "                sigma=df_[\"garch_vol\"].values,\n",
    "                option_type=option_flag\n",
    "            )\n",
    "\n",
    "            # ---- Log residual target ----\n",
    "            raw_resid = np.log(\n",
    "                (df_[price_col] + EPS) /\n",
    "                (df_[\"BS_PRICE\"] + EPS)\n",
    "            )\n",
    "\n",
    "            # ---- CLIP residuals ----\n",
    "            df_[\"TARGET\"] = np.clip(raw_resid, -RESID_CLIP, RESID_CLIP)\n",
    "\n",
    "            df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            df_.dropna(inplace=True)\n",
    "\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "\n",
    "        X_train = scaler_X.fit_transform(df_train[X_cols])\n",
    "        X_val   = scaler_X.transform(df_val[X_cols])\n",
    "        X_test  = scaler_X.transform(df_test[X_cols])\n",
    "\n",
    "        y_train = scaler_y.fit_transform(df_train[[\"TARGET\"]])\n",
    "        y_val   = scaler_y.transform(df_val[[\"TARGET\"]])\n",
    "        y_test  = scaler_y.transform(df_test[[\"TARGET\"]])\n",
    "\n",
    "        scaled[asset][opt_type] = {\n",
    "            \"X\": (X_train, X_val, X_test),\n",
    "            \"y\": (y_train, y_val, y_test),\n",
    "            \"scalers\": (scaler_X, scaler_y),\n",
    "            \"features\": X_cols,\n",
    "            \"price_col\": price_col\n",
    "        }\n",
    "\n",
    "        print(f\"[{asset} | {opt_type}] BS residuals (clipped) ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf75a5d-6140-44bb-b1aa-8f452d65dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Torch Dataset wrapper\n",
    "# ============================================================\n",
    "\n",
    "class OptionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa7501f-7c83-475f-bda3-7a71cec27b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY | CALL] loaders ready\n",
      "[SPY | PUT] loaders ready\n",
      "[AAPL | CALL] loaders ready\n",
      "[AAPL | PUT] loaders ready\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# PyTorch Dataset + DataLoader\n",
    "# --------------------------------------------------------\n",
    "# Notes:\n",
    "# - Keep tensors on CPU here (DataLoader works best on CPU tensors)\n",
    "# - Move batches to GPU inside the training loop (non_blocking=True)\n",
    "# - pin_memory=True speeds up CPU->GPU transfer\n",
    "# --------------------------------------------------------\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "loaders = {}\n",
    "\n",
    "for asset, asset_data in scaled.items():\n",
    "    loaders[asset] = {}\n",
    "\n",
    "    for opt_type, data in asset_data.items():\n",
    "        X_train, X_val, X_test = data[\"X\"]\n",
    "        y_train, y_val, y_test = data[\"y\"]\n",
    "\n",
    "        X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
    "        y_val_t   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "        X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "        y_test_t  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "        train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "        val_ds   = TensorDataset(X_val_t,   y_val_t)\n",
    "        test_ds  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "        pin = (device.type == \"cuda\")\n",
    "\n",
    "        loaders[asset][opt_type] = {\n",
    "            \"train\": DataLoader(\n",
    "                train_ds,\n",
    "                batch_size=4096,\n",
    "                shuffle=True,\n",
    "                num_workers=2,\n",
    "                pin_memory=pin,\n",
    "                persistent_workers=True\n",
    "            ),\n",
    "            \"val\": DataLoader(\n",
    "                val_ds,\n",
    "                batch_size=4096,\n",
    "                shuffle=False,\n",
    "                num_workers=2,\n",
    "                pin_memory=pin,\n",
    "                persistent_workers=True\n",
    "            ),\n",
    "            \"test\": DataLoader(\n",
    "                test_ds,\n",
    "                batch_size=4096,\n",
    "                shuffle=False,\n",
    "                num_workers=2,\n",
    "                pin_memory=pin,\n",
    "                persistent_workers=True\n",
    "            )\n",
    "        }\n",
    "\n",
    "        print(f\"[{asset} | {opt_type}] loaders ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e11614f1-b770-4a49-893e-069a45e01cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MLP baseline\n",
    "# ------------------------------------------------------------\n",
    "# This sets a performance floor.\n",
    "# If Transformer can't beat this → it's not worth the complexity.\n",
    "# ============================================================\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cca48e8-b066-4f3d-a166-cc9e6e84ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Transformer model (time-independent feature Transformer)\n",
    "# ------------------------------------------------------------\n",
    "# Uses self-attention over feature dimensions, not sequences.\n",
    "# Keeps dataset identical to MLP.\n",
    "# ============================================================\n",
    "\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, n_features, d_model=32, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Linear(1, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model * n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, n_features)\n",
    "        x = x.unsqueeze(-1)                 # (B, F, 1)\n",
    "        x = self.embed(x)                   # (B, F, d_model)\n",
    "        x = self.encoder(x)                 # (B, F, d_model)\n",
    "        x = x.flatten(start_dim=1)          # (B, F*d_model)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d5785c2-b178-45b2-9b82-6f8f396dd375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training MLP for SPY CALL\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.064965 | Val MSE: 0.037321\n",
      "Epoch 02 | Train MSE: 0.011377 | Val MSE: 0.019707\n",
      "Epoch 03 | Train MSE: 0.009334 | Val MSE: 0.018772\n",
      "Epoch 04 | Train MSE: 0.008584 | Val MSE: 0.015925\n",
      "Epoch 05 | Train MSE: 0.008173 | Val MSE: 0.016178\n",
      "Epoch 06 | Train MSE: 0.007997 | Val MSE: 0.013238\n",
      "Epoch 07 | Train MSE: 0.007732 | Val MSE: 0.013213\n",
      "Epoch 08 | Train MSE: 0.007533 | Val MSE: 0.012146\n",
      "Epoch 09 | Train MSE: 0.007465 | Val MSE: 0.011936\n",
      "Epoch 10 | Train MSE: 0.007293 | Val MSE: 0.012622\n",
      "\n",
      "==============================\n",
      " Training MLP for SPY PUT\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.069261 | Val MSE: 0.173126\n",
      "Epoch 02 | Train MSE: 0.013290 | Val MSE: 0.069413\n",
      "Epoch 03 | Train MSE: 0.007597 | Val MSE: 0.033945\n",
      "Epoch 04 | Train MSE: 0.006609 | Val MSE: 0.035345\n",
      "Epoch 05 | Train MSE: 0.006096 | Val MSE: 0.026810\n",
      "Epoch 06 | Train MSE: 0.005838 | Val MSE: 0.024536\n",
      "Epoch 07 | Train MSE: 0.005695 | Val MSE: 0.024690\n",
      "Epoch 08 | Train MSE: 0.005508 | Val MSE: 0.020029\n",
      "Epoch 09 | Train MSE: 0.005400 | Val MSE: 0.018770\n",
      "Epoch 10 | Train MSE: 0.005307 | Val MSE: 0.018042\n",
      "\n",
      "==============================\n",
      " Training MLP for AAPL CALL\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.189854 | Val MSE: 0.179137\n",
      "Epoch 02 | Train MSE: 0.069903 | Val MSE: 0.135435\n",
      "Epoch 03 | Train MSE: 0.056531 | Val MSE: 0.095508\n",
      "Epoch 04 | Train MSE: 0.042825 | Val MSE: 0.063235\n",
      "Epoch 05 | Train MSE: 0.028071 | Val MSE: 0.031725\n",
      "Epoch 06 | Train MSE: 0.018190 | Val MSE: 0.019413\n",
      "Epoch 07 | Train MSE: 0.015163 | Val MSE: 0.016653\n",
      "Epoch 08 | Train MSE: 0.013700 | Val MSE: 0.012754\n",
      "Epoch 09 | Train MSE: 0.012871 | Val MSE: 0.012029\n",
      "Epoch 10 | Train MSE: 0.012316 | Val MSE: 0.010868\n",
      "\n",
      "==============================\n",
      " Training MLP for AAPL PUT\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.198284 | Val MSE: 0.192202\n",
      "Epoch 02 | Train MSE: 0.062688 | Val MSE: 0.128177\n",
      "Epoch 03 | Train MSE: 0.055120 | Val MSE: 0.120985\n",
      "Epoch 04 | Train MSE: 0.048454 | Val MSE: 0.117445\n",
      "Epoch 05 | Train MSE: 0.037837 | Val MSE: 0.076928\n",
      "Epoch 06 | Train MSE: 0.025353 | Val MSE: 0.048254\n",
      "Epoch 07 | Train MSE: 0.018540 | Val MSE: 0.037822\n",
      "Epoch 08 | Train MSE: 0.015634 | Val MSE: 0.032307\n",
      "Epoch 09 | Train MSE: 0.014125 | Val MSE: 0.025447\n",
      "Epoch 10 | Train MSE: 0.013250 | Val MSE: 0.026219\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Training MLP models (WEIGHTED LOSS)\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS = 10\n",
    "results = {}\n",
    "\n",
    "for asset, asset_data in scaled.items():\n",
    "    results[asset] = {}\n",
    "\n",
    "    for opt_type, data in asset_data.items():\n",
    "        print(f\"\\n==============================\")\n",
    "        print(f\" Training MLP for {asset} {opt_type}\")\n",
    "        print(f\"==============================\")\n",
    "\n",
    "        train_loader = loaders[asset][opt_type][\"train\"]\n",
    "        val_loader   = loaders[asset][opt_type][\"val\"]\n",
    "\n",
    "        model = MLP(n_features=len(data[\"features\"])).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        best_val_mse = float(\"inf\")\n",
    "        best_state = None\n",
    "        patience = 2\n",
    "        patience_ctr = 0\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # -------- TRAIN --------\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "\n",
    "            for Xb, yb in train_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preds = model(Xb)\n",
    "\n",
    "                # -------- WEIGHTED MSE (KEY FIX) --------\n",
    "                weights = torch.clamp(torch.exp(-torch.abs(yb)), max=5.0)\n",
    "                loss = (weights * (preds - yb) ** 2).mean()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            # -------- VALIDATE --------\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for Xb, yb in val_loader:\n",
    "                    Xb = Xb.to(device, non_blocking=True)\n",
    "                    yb = yb.to(device, non_blocking=True)\n",
    "                    preds = model(Xb)\n",
    "                    val_losses.append(((preds - yb) ** 2).mean().item())\n",
    "\n",
    "            train_mse = np.mean(train_losses)\n",
    "            val_mse   = np.mean(val_losses)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:02d} | \"\n",
    "                f\"Train MSE: {train_mse:.6f} | \"\n",
    "                f\"Val MSE: {val_mse:.6f}\"\n",
    "            )\n",
    "\n",
    "            if val_mse < best_val_mse:\n",
    "                best_val_mse = val_mse\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_ctr = 0\n",
    "            else:\n",
    "                patience_ctr += 1\n",
    "                if patience_ctr >= patience:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        model.to(device)\n",
    "\n",
    "        results[asset][opt_type] = {\n",
    "            \"model\": model,\n",
    "            \"best_val_mse\": best_val_mse\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "babaa806-c4c8-4e9b-aa25-ddf60568ec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training Transformer for SPY CALL\n",
      "==============================\n",
      "Epoch 01 | Val MSE: 0.036280\n",
      "Epoch 02 | Val MSE: 0.030346\n",
      "Epoch 03 | Val MSE: 0.030056\n",
      "Epoch 04 | Val MSE: 0.022586\n",
      "Epoch 05 | Val MSE: 0.023081\n",
      "Epoch 06 | Val MSE: 0.025834\n",
      "\n",
      "==============================\n",
      " Training Transformer for SPY PUT\n",
      "==============================\n",
      "Epoch 01 | Val MSE: 0.175668\n",
      "Epoch 02 | Val MSE: 0.153540\n",
      "Epoch 03 | Val MSE: 0.147491\n",
      "Epoch 04 | Val MSE: 0.104321\n",
      "Epoch 05 | Val MSE: 0.103748\n",
      "Epoch 06 | Val MSE: 0.086345\n",
      "Epoch 07 | Val MSE: 0.133853\n",
      "Epoch 08 | Val MSE: 0.081005\n",
      "Epoch 09 | Val MSE: 0.115832\n",
      "Epoch 10 | Val MSE: 0.096886\n",
      "\n",
      "==============================\n",
      " Training Transformer for AAPL CALL\n",
      "==============================\n",
      "Epoch 01 | Val MSE: 0.028267\n",
      "Epoch 02 | Val MSE: 0.021278\n",
      "Epoch 03 | Val MSE: 0.020097\n",
      "Epoch 04 | Val MSE: 0.017161\n",
      "Epoch 05 | Val MSE: 0.018020\n",
      "Epoch 06 | Val MSE: 0.018489\n",
      "\n",
      "==============================\n",
      " Training Transformer for AAPL PUT\n",
      "==============================\n",
      "Epoch 01 | Val MSE: 0.053091\n",
      "Epoch 02 | Val MSE: 0.046072\n",
      "Epoch 03 | Val MSE: 0.038626\n",
      "Epoch 04 | Val MSE: 0.039831\n",
      "Epoch 05 | Val MSE: 0.032174\n",
      "Epoch 06 | Val MSE: 0.036796\n",
      "Epoch 07 | Val MSE: 0.042362\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Training Transformer models (WEIGHTED LOSS)\n",
    "# ============================================================\n",
    "\n",
    "transformer_results = {}\n",
    "\n",
    "for asset, asset_data in scaled.items():\n",
    "    transformer_results[asset] = {}\n",
    "\n",
    "    for opt_type, data in asset_data.items():\n",
    "        print(f\"\\n==============================\")\n",
    "        print(f\" Training Transformer for {asset} {opt_type}\")\n",
    "        print(f\"==============================\")\n",
    "\n",
    "        train_loader = loaders[asset][opt_type][\"train\"]\n",
    "        val_loader   = loaders[asset][opt_type][\"val\"]\n",
    "\n",
    "        model = TransformerRegressor(\n",
    "            n_features=len(data[\"features\"])\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        best_val_mse = float(\"inf\")\n",
    "        best_state = None\n",
    "        patience = 2\n",
    "        patience_ctr = 0\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # -------- TRAIN --------\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "\n",
    "            for Xb, yb in train_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preds = model(Xb)\n",
    "\n",
    "                weights = torch.clamp(torch.exp(-torch.abs(yb)), max=5.0)\n",
    "                loss = (weights * (preds - yb) ** 2).mean()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            # -------- VALIDATE --------\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for Xb, yb in val_loader:\n",
    "                    Xb = Xb.to(device, non_blocking=True)\n",
    "                    yb = yb.to(device, non_blocking=True)\n",
    "                    preds = model(Xb)\n",
    "                    val_losses.append(((preds - yb) ** 2).mean().item())\n",
    "\n",
    "            val_mse = np.mean(val_losses)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:02d} | \"\n",
    "                f\"Val MSE: {val_mse:.6f}\"\n",
    "            )\n",
    "\n",
    "            if val_mse < best_val_mse:\n",
    "                best_val_mse = val_mse\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_ctr = 0\n",
    "            else:\n",
    "                patience_ctr += 1\n",
    "                if patience_ctr >= patience:\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "        model.to(device)\n",
    "\n",
    "        transformer_results[asset][opt_type] = {\n",
    "            \"model\": model\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6de4071-2849-4105-b458-b38f64722d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "VAL RESULTS (BS + ML, CLIPPED)\n",
      "==============================\n",
      "SPY CALL | MLP MAE: 3.404 (6.57%) | RMSE: 6.245 (12.05%) || TF MAE: 3.950 (7.62%) | RMSE: 6.547 (12.63%)\n",
      "SPY PUT | MLP MAE: 6.745 (28.33%) | RMSE: 11.248 (47.24%) || TF MAE: 7.900 (33.18%) | RMSE: 12.135 (50.97%)\n",
      "AAPL CALL | MLP MAE: 2.294 (6.81%) | RMSE: 4.534 (13.45%) || TF MAE: 2.834 (8.41%) | RMSE: 5.048 (14.98%)\n",
      "AAPL PUT | MLP MAE: 3.034 (11.93%) | RMSE: 5.247 (20.63%) || TF MAE: 2.930 (11.52%) | RMSE: 5.253 (20.65%)\n",
      "\n",
      "==============================\n",
      "TEST RESULTS (BS + ML, CLIPPED)\n",
      "==============================\n",
      "SPY CALL | MLP MAE: 5.437 (10.49%) | RMSE: 8.654 (16.70%) || TF MAE: 5.451 (10.52%) | RMSE: 9.158 (17.67%)\n",
      "SPY PUT | MLP MAE: 6.459 (31.86%) | RMSE: 10.495 (51.77%) || TF MAE: 6.044 (29.81%) | RMSE: 9.551 (47.11%)\n",
      "AAPL CALL | MLP MAE: 2.376 (9.90%) | RMSE: 4.696 (19.57%) || TF MAE: 2.870 (11.96%) | RMSE: 5.085 (21.19%)\n",
      "AAPL PUT | MLP MAE: 3.277 (9.62%) | RMSE: 5.105 (14.98%) || TF MAE: 2.775 (8.14%) | RMSE: 4.916 (14.42%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluation in PRICE SPACE (BS + ML residual) — CLIPPED\n",
    "# ============================================================\n",
    "# This version prevents exponential blow-ups by clipping\n",
    "# log-residual predictions to a realistic range.\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_bs_residual(\n",
    "    model, loader, scaler_y,\n",
    "    base_df, price_col, opt_type,\n",
    "    risk_free_rate=0.02,\n",
    "    clip_value=2.0   # <-- KEY PARAMETER\n",
    "):\n",
    "    \"\"\"\n",
    "    clip_value = 2.0 means:\n",
    "      exp(-2) ≈ 0.14\n",
    "      exp(+2) ≈ 7.39\n",
    "    which already allows very large option mispricing.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Predict residuals (log-space)\n",
    "    # --------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        for Xb, _ in loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            preds.append(model(Xb).cpu().numpy())\n",
    "\n",
    "    preds = scaler_y.inverse_transform(np.vstack(preds)).ravel()\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # CLIP RESIDUALS (CRITICAL FIX)\n",
    "    # --------------------------------------------\n",
    "    preds = np.clip(preds, -clip_value, clip_value)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Recompute BS prices at time t\n",
    "    # --------------------------------------------\n",
    "    option_flag = \"call\" if opt_type == \"CALL\" else \"put\"\n",
    "\n",
    "    bs_prices = black_scholes_price(\n",
    "        S=base_df[\"UNDERLYING_LAST\"].values,\n",
    "        K=base_df[\"STRIKE\"].values,\n",
    "        T=base_df[\"DTE\"].values / 365.0,\n",
    "        r=risk_free_rate,\n",
    "        sigma=base_df[\"garch_vol\"].values,\n",
    "        option_type=option_flag\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # True market prices\n",
    "    # --------------------------------------------\n",
    "    true_prices = base_df[price_col].values\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Reconstruct predicted prices\n",
    "    # --------------------------------------------\n",
    "    pred_prices = bs_prices * np.exp(preds)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Metrics\n",
    "    # --------------------------------------------\n",
    "    mae  = mean_absolute_error(true_prices, pred_prices)\n",
    "    rmse = np.sqrt(mean_squared_error(true_prices, pred_prices))\n",
    "\n",
    "    mae_pct  = 100 * mae / np.mean(true_prices)\n",
    "    rmse_pct = 100 * rmse / np.mean(true_prices)\n",
    "\n",
    "    return mae, rmse, mae_pct, rmse_pct\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run evaluation (VAL first, then TEST)\n",
    "# ============================================================\n",
    "\n",
    "for split_name in [\"val\", \"test\"]:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"{split_name.upper()} RESULTS (BS + ML, CLIPPED)\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    for asset, asset_data in scaled.items():\n",
    "        for opt_type, data in asset_data.items():\n",
    "\n",
    "            loader = loaders[asset][opt_type][split_name]\n",
    "            model_mlp = results[asset][opt_type][\"model\"]\n",
    "            model_tf  = transformer_results[asset][opt_type][\"model\"]\n",
    "\n",
    "            price_col = data[\"price_col\"]\n",
    "\n",
    "            # Base dataframe aligned to loader length\n",
    "            base_df = splits[asset][split_name].copy()\n",
    "            base_df = base_df.loc[base_df[price_col] > 0].copy()\n",
    "            base_df = base_df.iloc[:len(loader.dataset)]\n",
    "\n",
    "            mlp_metrics = evaluate_bs_residual(\n",
    "                model_mlp,\n",
    "                loader,\n",
    "                data[\"scalers\"][1],\n",
    "                base_df,\n",
    "                price_col,\n",
    "                opt_type\n",
    "            )\n",
    "\n",
    "            tf_metrics = evaluate_bs_residual(\n",
    "                model_tf,\n",
    "                loader,\n",
    "                data[\"scalers\"][1],\n",
    "                base_df,\n",
    "                price_col,\n",
    "                opt_type\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"{asset} {opt_type} | \"\n",
    "                f\"MLP MAE: {mlp_metrics[0]:.3f} ({mlp_metrics[2]:.2f}%) | \"\n",
    "                f\"RMSE: {mlp_metrics[1]:.3f} ({mlp_metrics[3]:.2f}%) || \"\n",
    "                f\"TF MAE: {tf_metrics[0]:.3f} ({tf_metrics[2]:.2f}%) | \"\n",
    "                f\"RMSE: {tf_metrics[1]:.3f} ({tf_metrics[3]:.2f}%)\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea15d3d-2524-4711-91ec-180fbf5dc5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Option Pricing (WSL)",
   "language": "python",
   "name": "option_pricing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
