{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89b4391-0d40-4b20-90e9-6a7921d911f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Core numerical libraries\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# PyTorch (MLP model)\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# Scaling and metrics\n",
    "# ============================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility\n",
    "# ============================================================\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94310362-ed21-41fd-86e5-e998f1e038b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5080\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available (WSL should expose GPU through NVIDIA drivers)\n",
    "# However since pytorch cuda = 12.8 work with latest blackwell RTX5080\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175bff18-8426-437b-9515-02d7112ab700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] options rows: 4195810\n",
      "[SPY] daily rows: 3521\n",
      "[AAPL] options rows: 1562105\n",
      "[AAPL] daily rows: 2011\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load CLEAN datasets (already prepared earlier)\n",
    "# ------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "ASSETS = {\n",
    "    \"SPY\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_SPY.csv\",\n",
    "        \"daily\":   DATA_DIR / \"spy_with_garch.csv\",\n",
    "        \"daily_date_col\": \"Date\",\n",
    "        \"daily_close_col\": \"Close\"\n",
    "    },\n",
    "    \"AAPL\": {\n",
    "        \"options\": DATA_DIR / \"options_clean_AAPL.csv\",\n",
    "        \"daily\":   DATA_DIR / \"aapl_with_garch.csv\",  # you must create this in Notebook 02\n",
    "        \"daily_date_col\": \"Date\",\n",
    "        \"daily_close_col\": \"Close\"\n",
    "    }\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for asset, cfg in ASSETS.items():\n",
    "    opts = pd.read_csv(cfg[\"options\"])\n",
    "    daily = pd.read_csv(cfg[\"daily\"], parse_dates=[cfg[\"daily_date_col\"]])\n",
    "\n",
    "    opts[\"QUOTE_DATE\"]  = pd.to_datetime(opts[\"QUOTE_DATE\"],  format=\"mixed\", errors=\"coerce\")\n",
    "    opts[\"EXPIRE_DATE\"] = pd.to_datetime(opts[\"EXPIRE_DATE\"], format=\"mixed\", errors=\"coerce\")\n",
    "    opts = opts.dropna(subset=[\"QUOTE_DATE\", \"EXPIRE_DATE\"])\n",
    "\n",
    "    daily = daily.sort_values(cfg[\"daily_date_col\"]).reset_index(drop=True)\n",
    "\n",
    "    datasets[asset] = {\n",
    "        \"opts\": opts,\n",
    "        \"daily\": daily\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] options rows:\", len(opts))\n",
    "    print(f\"[{asset}] daily rows:\", len(daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b92b68e-cc60-457b-a4c3-c120af06adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] merged rows: 4169845\n",
      "[AAPL] merged rows: 1552960\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Merge SPY and AAPL macro features into option dataset\n",
    "# ------------------------------------------------------------\n",
    "# Why?\n",
    "# - Options prices depend on:\n",
    "#   • underlying level\n",
    "#   • market returns\n",
    "#   • volatility regime\n",
    "# ============================================================\n",
    "\n",
    "merged_data = {}\n",
    "\n",
    "for asset, data_dict in datasets.items():\n",
    "    opts = data_dict[\"opts\"]\n",
    "    daily = data_dict[\"daily\"]\n",
    "\n",
    "    daily_small = daily[[\"Date\", \"Close\", \"log_return\", \"garch_vol\"]].copy()\n",
    "    daily_small = daily_small.rename(columns={\n",
    "        \"Date\": \"QUOTE_DATE\",\n",
    "        \"Close\": f\"{asset}_CLOSE\"\n",
    "    })\n",
    "\n",
    "    opts[\"QUOTE_DATE\"] = pd.to_datetime(opts[\"QUOTE_DATE\"])\n",
    "    daily_small[\"QUOTE_DATE\"] = pd.to_datetime(daily_small[\"QUOTE_DATE\"])\n",
    "\n",
    "    merged = opts.merge(daily_small, on=\"QUOTE_DATE\", how=\"left\")\n",
    "    merged = merged.dropna(subset=[\"log_return\", \"garch_vol\", f\"{asset}_CLOSE\"])\n",
    "\n",
    "    merged_data[asset] = merged\n",
    "\n",
    "    print(f\"[{asset}] merged rows:\", len(merged))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d47c3d-3858-4538-a8f0-d0892c470a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Feature selection\n",
    "# ------------------------------------------------------------\n",
    "# These are standard option pricing drivers:\n",
    "#\n",
    "# UNDERLYING_LAST → spot price\n",
    "# SPY_CLOSE       → market level\n",
    "# log_return      → return shock\n",
    "# garch_vol       → volatility regime\n",
    "# DTE             → time decay\n",
    "# MONEINESS       → intrinsic structure\n",
    "# ============================================================\n",
    "\n",
    "feature_cols_base = [\n",
    "    \"UNDERLYING_LAST\",\n",
    "    \"log_return\",\n",
    "    \"garch_vol\",\n",
    "    \"DTE\",\n",
    "    \"MONEINESS\"\n",
    "]\n",
    "\n",
    "# Target: Call option mid price\n",
    "target_col = \"C_MID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4900ba02-08e4-4c30-a9f4-e31c6cd479c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SPY] split:\n",
      "  Train: 2330311\n",
      "  Val  : 1024018\n",
      "  Test : 815516\n",
      "\n",
      "[AAPL] split:\n",
      "  Train: 1204151\n",
      "  Val  : 161572\n",
      "  Test : 187237\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 80/10/10 split (time-based split)\n",
    "# ============================================================\n",
    "\n",
    "splits = {}\n",
    "\n",
    "for asset, df in merged_data.items():\n",
    "    df = df.sort_values(\"QUOTE_DATE\").reset_index(drop=True)\n",
    "\n",
    "    unique_dates = df[\"QUOTE_DATE\"].sort_values().unique()\n",
    "    n_dates = len(unique_dates)\n",
    "\n",
    "    train_cut = int(0.8 * n_dates)\n",
    "    val_cut   = int(0.9 * n_dates)\n",
    "\n",
    "    train_dates = unique_dates[:train_cut]\n",
    "    val_dates   = unique_dates[train_cut:val_cut]\n",
    "    test_dates  = unique_dates[val_cut:]\n",
    "\n",
    "    train_data = df[df[\"QUOTE_DATE\"].isin(train_dates)]\n",
    "    val_data   = df[df[\"QUOTE_DATE\"].isin(val_dates)]\n",
    "    test_data  = df[df[\"QUOTE_DATE\"].isin(test_dates)]\n",
    "\n",
    "    splits[asset] = {\n",
    "        \"train\": train_data,\n",
    "        \"val\":   val_data,\n",
    "        \"test\":  test_data\n",
    "    }\n",
    "\n",
    "    print(f\"\\n[{asset}] split:\")\n",
    "    print(\"  Train:\", len(train_data))\n",
    "    print(\"  Val  :\", len(val_data))\n",
    "    print(\"  Test :\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1bc820-2e05-4d78-b1a8-4a05bb4717ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = {}\n",
    "\n",
    "for asset, split in splits.items():\n",
    "    X_cols = feature_cols_base + [f\"{asset}_CLOSE\"]\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_train = scaler_X.fit_transform(split[\"train\"][X_cols])\n",
    "    X_val   = scaler_X.transform(split[\"val\"][X_cols])\n",
    "    X_test  = scaler_X.transform(split[\"test\"][X_cols])\n",
    "\n",
    "    y_train = scaler_y.fit_transform(split[\"train\"][[target_col]])\n",
    "    y_val   = scaler_y.transform(split[\"val\"][[target_col]])\n",
    "    y_test  = scaler_y.transform(split[\"test\"][[target_col]])\n",
    "\n",
    "    scaled[asset] = {\n",
    "        \"X\": (X_train, X_val, X_test),\n",
    "        \"y\": (y_train, y_val, y_test),\n",
    "        \"scalers\": (scaler_X, scaler_y),\n",
    "        \"features\": X_cols\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf75a5d-6140-44bb-b1aa-8f452d65dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Torch Dataset wrapper\n",
    "# ============================================================\n",
    "\n",
    "class OptionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa7501f-7c83-475f-bda3-7a71cec27b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPY] loaders ready\n",
      "[AAPL] loaders ready\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# PyTorch Dataset + DataLoader\n",
    "# --------------------------------------------------------\n",
    "# Notes:\n",
    "# - Keep tensors on CPU here (DataLoader works best on CPU tensors)\n",
    "# - Move batches to GPU inside the training loop (non_blocking=True)\n",
    "# - pin_memory=True speeds up CPU->GPU transfer\n",
    "# --------------------------------------------------------\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "loaders = {}\n",
    "\n",
    "for asset, data in scaled.items():\n",
    "    X_train, X_val, X_test = data[\"X\"]\n",
    "    y_train, y_val, y_test = data[\"y\"]\n",
    "\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
    "    y_val_t   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "    X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "    y_test_t  = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    val_ds   = TensorDataset(X_val_t,   y_val_t)\n",
    "    test_ds  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "    pin = (device.type == \"cuda\")\n",
    "\n",
    "    loaders[asset] = {\n",
    "        \"train\": DataLoader(\n",
    "            train_ds, batch_size=4096, shuffle=True,\n",
    "            num_workers=2, pin_memory=pin, persistent_workers=True\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            val_ds, batch_size=4096, shuffle=False,\n",
    "            num_workers=2, pin_memory=pin, persistent_workers=True\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            test_ds, batch_size=4096, shuffle=False,\n",
    "            num_workers=2, pin_memory=pin, persistent_workers=True\n",
    "        )\n",
    "    }\n",
    "\n",
    "    print(f\"[{asset}] loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11614f1-b770-4a49-893e-069a45e01cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MLP baseline\n",
    "# ------------------------------------------------------------\n",
    "# This sets a performance floor.\n",
    "# If Transformer can't beat this → it's not worth the complexity.\n",
    "# ============================================================\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5785c2-b178-45b2-9b82-6f8f396dd375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training MLP for SPY\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.089446 | Val MSE: 0.046459\n",
      "Epoch 02 | Train MSE: 0.003775 | Val MSE: 0.020446\n",
      "Epoch 03 | Train MSE: 0.001729 | Val MSE: 0.014623\n",
      "Epoch 04 | Train MSE: 0.001152 | Val MSE: 0.011621\n",
      "Epoch 05 | Train MSE: 0.000953 | Val MSE: 0.012613\n",
      "Epoch 06 | Train MSE: 0.000848 | Val MSE: 0.012253\n",
      "Early stopping triggered at epoch 6\n",
      "\n",
      "==============================\n",
      " Training MLP for AAPL\n",
      "==============================\n",
      "Epoch 01 | Train MSE: 0.256753 | Val MSE: 0.026270\n",
      "Epoch 02 | Train MSE: 0.014129 | Val MSE: 0.017773\n",
      "Epoch 03 | Train MSE: 0.008422 | Val MSE: 0.016182\n",
      "Epoch 04 | Train MSE: 0.005390 | Val MSE: 0.016322\n",
      "Epoch 05 | Train MSE: 0.003553 | Val MSE: 0.014702\n",
      "Epoch 06 | Train MSE: 0.002388 | Val MSE: 0.011139\n",
      "Epoch 07 | Train MSE: 0.001686 | Val MSE: 0.009594\n",
      "Epoch 08 | Train MSE: 0.001265 | Val MSE: 0.006832\n",
      "Epoch 09 | Train MSE: 0.001002 | Val MSE: 0.006233\n",
      "Epoch 10 | Train MSE: 0.000804 | Val MSE: 0.007173\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Training (GPU-enabled)\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS = 10\n",
    "results = {}\n",
    "\n",
    "for asset, data in scaled.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Training MLP for {asset}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    feature_cols = data[\"features\"]\n",
    "    train_loader = loaders[asset][\"train\"]\n",
    "    val_loader   = loaders[asset][\"val\"]\n",
    "\n",
    "    model = MLP(n_features=len(feature_cols)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "\n",
    "    best_val_mse = float(\"inf\")\n",
    "    best_state   = None\n",
    "    best_epoch   = None\n",
    "    patience     = 2          # stop if no improvement for 2 epochs\n",
    "    patience_ctr = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # -------- TRAIN --------\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "    \n",
    "        for Xb, yb in train_loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "    \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds = model(Xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_losses.append(loss.item())\n",
    "    \n",
    "        # -------- VALIDATE --------\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb = Xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "    \n",
    "                preds = model(Xb)\n",
    "                loss = loss_fn(preds, yb)\n",
    "                val_losses.append(loss.item())\n",
    "    \n",
    "        train_mse = float(np.mean(train_losses))\n",
    "        val_mse   = float(np.mean(val_losses))\n",
    "    \n",
    "        train_history.append(train_mse)\n",
    "        val_history.append(val_mse)\n",
    "    \n",
    "        print(\n",
    "            f\"Epoch {epoch+1:02d} | \"\n",
    "            f\"Train MSE: {train_mse:.6f} | \"\n",
    "            f\"Val MSE: {val_mse:.6f}\"\n",
    "        )\n",
    "    \n",
    "        # -------- EARLY STOPPING --------\n",
    "        if val_mse < best_val_mse:\n",
    "            best_val_mse = val_mse\n",
    "            best_state   = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            best_epoch   = epoch + 1\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    model = model.to(device)\n",
    "\n",
    "    results[asset] = {\n",
    "        \"model\": model,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"best_val_mse\": best_val_mse,\n",
    "        \"train_mse\": train_history,\n",
    "        \"val_mse\": val_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6de4071-2849-4105-b458-b38f64722d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Test evaluation for SPY\n",
      "==============================\n",
      "[SPY] Test RMSE: 5.4851  (10.58%)\n",
      "[SPY] Test MAE : 4.1243  (7.96%)\n",
      "\n",
      "==============================\n",
      " Test evaluation for AAPL\n",
      "==============================\n",
      "[AAPL] Test RMSE: 2.7421  (11.43%)\n",
      "[AAPL] Test MAE : 2.1292  (8.87%)\n"
     ]
    }
   ],
   "source": [
    "for asset, data in scaled.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Test evaluation for {asset}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    model = results[asset][\"model\"]\n",
    "    test_loader = loaders[asset][\"test\"]\n",
    "    scaler_y = data[\"scalers\"][1]\n",
    "\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    true_list  = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb = Xb.to(device, non_blocking=True)\n",
    "            preds = model(Xb)\n",
    "\n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "            true_list.append(yb.cpu().numpy())\n",
    "\n",
    "    preds = scaler_y.inverse_transform(np.vstack(preds_list))\n",
    "    true  = scaler_y.inverse_transform(np.vstack(true_list))\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true, preds))\n",
    "    mae  = mean_absolute_error(true, preds)\n",
    "\n",
    "    mean_price = true.mean()\n",
    "    rmse_pct = 100 * rmse / mean_price\n",
    "    mae_pct  = 100 * mae  / mean_price\n",
    "\n",
    "    print(f\"[{asset}] Test RMSE: {rmse:.4f}  ({rmse_pct:.2f}%)\")\n",
    "    print(f\"[{asset}] Test MAE : {mae:.4f}  ({mae_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea15d3d-2524-4711-91ec-180fbf5dc5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Option Pricing (WSL)",
   "language": "python",
   "name": "option_pricing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
